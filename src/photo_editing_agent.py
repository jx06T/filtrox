import json
import re
from typing import List, Dict, Any, Optional

from .llm_backend import BaseLLM , Gemini
from dotenv import load_dotenv

# å‡è¨­é€™æ˜¯å¾žæ‚¨çš„ Snippet 3 å¼•å…¥çš„
# from ai_engine_module import AIEngine 


class PhotoEditingAgent:
    """
    å°ˆé–€ç”¨æ–¼æŽ§åˆ¶ Darktable 'colorbalancergb' æ¨¡çµ„çš„ AI ä»£ç†
    """
    def __init__(self, llm_provider: BaseLLM):
        self.llm = llm_provider
        
        # === é—œéµï¼šé€™è£¡çš„ Schema å¿…é ˆåš´æ ¼å°æ‡‰ Darktable C Struct çš„è®Šæ•¸å ===
        # åƒè€ƒå‰é¢çš„ binary layout ä»£ç¢¼ï¼šFIELD_ORDER_32F
        self.param_schema = {
            # --- 4-Way Controls (Shadows, Midtones, Highlights, Global) ---
            # C = Chroma (Saturation), Y = Luminance (Brightness), H = Hue
            "global_C": "float (-0.5 to 0.5) - Global Saturation adjustment",
            "global_Y": "float (-0.5 to 0.5) - Global Brightness",
            "global_H": "float (-180 to 180) - Global Hue Tint",
            
            "shadows_C": "float (-0.5 to 0.5) - Shadows Saturation",
            "shadows_Y": "float (-0.3 to 0.3) - Shadows Brightness",
            "shadows_H": "float (0 to 360) - Shadows Hue Tint",
            
            "midtones_C": "float (-0.5 to 0.5) - Midtones Saturation",
            "midtones_Y": "float (-0.3 to 0.3) - Midtones Brightness",
            "midtones_H": "float (0 to 360) - Midtones Hue Tint",
            
            "highlights_C": "float (-0.5 to 0.5) - Highlights Saturation",
            "highlights_Y": "float (-0.3 to 0.3) - Highlights Brightness",
            "highlights_H": "float (0 to 360) - Highlights Hue Tint",
            
            # --- Master Controls ---
            "contrast": "float (-0.5 to 0.5) - Global Contrast center",
            "vibrance": "float (-0.5 to 0.5) - Smart saturation (Vibrance)",
            "saturation_global": "float (0.0 to 2.0) - Linear Saturation Multiplier (Default 1.0)",
            
            # --- Optional (Fulcrums) ---
            # "white_fulcrum": "float - Defines what is considered white (Default 0.0)"
        }

    def _get_system_instruction(self) -> str:
        # load from system_prompt.md
        system_prompt = ""
        with open("system_prompt.md", "r", encoding="utf-8") as f:
            system_prompt = f.read()
        return system_prompt

    def _clean_json_output(self, raw_text: str) -> str:
        """æ¸…ç† LLM çš„è¼¸å‡º"""
        text = raw_text.strip()
        pattern = r"```(?:json)?\s*(.*?)\s*```"
        match = re.search(pattern, text, re.DOTALL)
        if match:
            text = match.group(1)
        return text

    def _execute_prompt(self, task_prompt: str) -> List[Dict[str, Any]]:
        """åŸ·è¡Œ Prompt ä¸¦è§£æžçµæžœ"""
        full_prompt = f"{self._get_system_instruction()}\n\n---\n\n{task_prompt}"

        raw_response = self.llm.generate_text(full_prompt)
        raw_response = raw_response.replace('```json', '')  # æœ‰æ™‚å€™æœƒå¤šå€‹ json æ¨™ç±¤ï¼Œå…ˆæ›¿æ›æŽ‰
        raw_response = raw_response.replace('```', '')
        print(raw_response)

        raw_json = json.loads(self._clean_json_output(raw_response))

        return raw_json['configs']

    def _format_disliked_factors(self, disliked_factors: Optional[Dict[str, List[float]]]) -> str:
        if not disliked_factors:
            return ""
        compact = {k: v for k, v in disliked_factors.items() if isinstance(v, list) and v}
        if not compact:
            return ""
        return f"\nDisliked factor values (avoid these numbers or close neighbors): {json.dumps(compact)}"

    def _format_preferred_factors(self, preferred_factors: Optional[Dict[str, float]]) -> str:
        if not preferred_factors:
            return ""
        return f"\nPreferred factor center (stay close to these values): {json.dumps(preferred_factors)}"

    def _format_variation_scale(self, variation_scale: Optional[float]) -> str:
        if variation_scale is None:
            return ""
        return f"\nVariation scale: {variation_scale} (lower means smaller changes around preferred factors)."

    # ================= æ¥­å‹™å ´æ™¯æ–¹æ³• =================

    def cold_start(self, user_request: str) -> List[Dict]:
        """å ´æ™¯ 1: å†·å•Ÿå‹• (Cold Start)"""
        prompt = f"""
        **Task: Cold Start Generation**
        User Request: "{user_request}"
        
        Goal: Generate 3 DISTINCT visual styles using strictly Color Balance RGB parameters.
        Example: 
        - If request is "Warm Cinematic", focus on 'midtones_H' (orange) and 'shadows_H' (teal).
        - If request is "High Contrast B&W", set 'saturation_global' to 0 and boost 'contrast'.
        """
        return self._execute_prompt(prompt)

    def auto_iterate(
        self,
        current_params: Dict,
        disliked_factors: Optional[Dict[str, List[float]]] = None,
        preferred_factors: Optional[Dict[str, float]] = None,
        variation_scale: Optional[float] = None,
    ) -> List[Dict]:
        """å ´æ™¯ 2: è‡ªå‹•è¿­ä»£ (Auto Iteration) - ä¸éœ€æç¤ºè©ž"""
        prompt = f"""
        **Task: Refinement (Auto-Iteration)**
        The user selected this specific style:
        {json.dumps(current_params)}
        {self._format_disliked_factors(disliked_factors)}
        {self._format_preferred_factors(preferred_factors)}
        {self._format_variation_scale(variation_scale)}
        
        Goal: Generate 3 variations based on this baseline:
        1. "Polished": Keep the vibe but fix potential issues (e.g. check if skin tones/midtones look natural).
        2. "Intensified": Push the color grading stronger (increase Chroma/Contrast values).
        3. "Softened": Reduce the effect intensity (bring values closer to 0).
        Keep variations closer to preferred factors as iterations increase.
        Always include the required "factors" object for each config.
        """
        return self._execute_prompt(prompt)

    def text_refine(
        self,
        current_params: Dict,
        user_feedback: str,
        disliked_factors: Optional[Dict[str, List[float]]] = None,
        preferred_factors: Optional[Dict[str, float]] = None,
        variation_scale: Optional[float] = None,
    ) -> List[Dict]:
        """å ´æ™¯ 3: æŒ‡å®šä¿®é£¾ (Text Refinement)"""
        prompt = f"""
        **Task: Specific Adjustment**
        Base Parameters: {json.dumps(current_params)}
        User Feedback: "{user_feedback}"
        {self._format_disliked_factors(disliked_factors)}
        {self._format_preferred_factors(preferred_factors)}
        {self._format_variation_scale(variation_scale)}
        
        Goal: Apply the feedback to the Base Parameters.
        Generate 3 versions: Subtle change, Moderate change, Strong change.
        Keep variations closer to preferred factors as iterations increase.
        Always include the required "factors" object for each config.
        """
        return self._execute_prompt(prompt)
    


if __name__ == "__main__":
    import os
    
    # 1. è¨­ç½® API Key
    load_dotenv()  
    api_key = os.getenv("GEMINI_API_KEY")
    
    # 2. åˆå§‹åŒ– Infrastructure
    llm_service = Gemini(api_key=api_key)
    
    # 3. åˆå§‹åŒ– Agent (æ³¨å…¥ GeminiService)
    agent = PhotoEditingAgent(llm_provider=llm_service)
    
    # 4. æ¸¬è©¦ Cold Start
    print("ðŸ¤– æ­£åœ¨ç”Ÿæˆ 'è³½åšé¾å…‹' é¢¨æ ¼...")
    variations = agent.cold_start("Cyberpunk style, neon lights")
    
    if variations:
        selected = variations[0]
        print(f"\nâœ… é¸æ“‡æ–¹æ¡ˆ: {selected['name']}")
        print(f"ðŸ“ ç†ç”±: {selected['reasoning']}")
        print(f"ðŸ”§ åƒæ•¸: {json.dumps(selected['parameters'], indent=2)}")
        
        # 5. æ¸¬è©¦ Auto Iterate (å‡è¨­ä½¿ç”¨è€…é»žäº†é€™å¼µåœ–)
        print("\nðŸ¤– æ­£åœ¨åŸºæ–¼é¸æ“‡é€²è¡Œè‡ªå‹•è¿­ä»£...")
        refined_vars = agent.auto_iterate(selected['parameters'])
        
        for idx, var in enumerate(refined_vars):
            print(f"  > è®Šé«” {idx+1}: {var['name']} - {var['reasoning']}")
